{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchTutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXWxiupmIOke"
      },
      "source": [
        "# PyTorch Tutorial\n",
        "\n",
        "Neste notebook vamos estudar a biblioteca [PyTorch](https://pytorch.org/) e seus fundamentos.\n",
        "\n",
        "Existem diveras maneiras de instalar o PyTorch, visite o [site oficial](https://pytorch.org/get-started/locally/) para mais detalhes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6mklmgsJF7t"
      },
      "source": [
        "## Tensor\n",
        "\n",
        "Primeiramente vamos aprender como trabalhar com [Tensors](https://pytorch.org/docs/stable/tensors.html), que são matrizes multidimensionais que contém elementos de um único tipo de dados.\n",
        "\n",
        "Veremos como criá-los e algumas operações básicas com eles, assim como converter de [arrays NumPy](https://numpy.org/doc/stable/reference/generated/numpy.array.html) para Tensors e vice-versa.\n",
        "\n",
        "Em PyTorch, basicamente tudo é baseado em operações de Tensors, um Tensor pode ter diferentes dimensões (1D, 2D, 3D, etc).\n",
        "\n",
        "Começaremos criando um Tensor vazio:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOvFI3ZJ6Ye",
        "outputId": "ed384574-4e50-4715-a423-730bbbf1bdd8"
      },
      "source": [
        "import torch\n",
        "\n",
        "x = torch.empty(1)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([8.8433e+18])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udjWmmdtKQta"
      },
      "source": [
        "Dessa forma, temos um [Scalar](https://en.wikipedia.org/wiki/Scalar_(physics)).\n",
        "\n",
        "Podemos mudar para um vector de 1 dimensão ao alterar o argumento de **empty**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLUYAIlBKjFT",
        "outputId": "9347ccbf-d26d-419e-9cb4-42470f38120b"
      },
      "source": [
        "x = torch.empty(3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([8.8445e+18, 3.0737e-41, 3.3631e-44])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwQWsmOhKnkO"
      },
      "source": [
        "Agora temos 3 itens em nosso Tensor.\n",
        "\n",
        "Também podemos fazê-lo de 2 dimensões ao passar dois argumentos (linhas e colunas):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZ_ZMf2KxXl",
        "outputId": "64d8f0c6-ceea-4989-c1a8-d924e94a8329"
      },
      "source": [
        "x = torch.empty(2, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[8.8448e+18, 3.0737e-41, 4.4842e-44],\n",
            "        [0.0000e+00,        nan, 1.3593e-43]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI6hQ0-SK4Za"
      },
      "source": [
        "Seguindo a mesma lógica, podemos torná-lo em um Tensor de 3 dimensões:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GODC02OK9kg",
        "outputId": "666cbc00-03ac-4f75-d306-4acd1ab8140f"
      },
      "source": [
        "x = torch.empty(2, 2, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[9.2062e+18, 3.0737e-41, 3.3631e-44],\n",
            "         [2.0000e+00, 0.0000e+00, 2.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 2.0000e+00, 0.0000e+00],\n",
            "         [2.0000e+00, 6.0289e-01, 9.3184e-01]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQuFvFC4LG3J"
      },
      "source": [
        "Até mesmo 4 dimensões é possível, porém torna-se difícil de visualizarmos e compreendermos, por isso vamos nos limitar até 3 dimensões.\n",
        "\n",
        "Também podemos criar um Tensor com valores aleatórios, por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Q9XBPwLTUb",
        "outputId": "a7bdd8e6-ccb5-467b-a571-73587cbc49f5"
      },
      "source": [
        "x = torch.rand(2, 2)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7913, 0.7339],\n",
            "        [0.9869, 0.0273]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWhlp9zNLYHV"
      },
      "source": [
        "É possível também criarmos um Tensor somente com 0's:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-f7A881LffE",
        "outputId": "468001c8-5dc7-4c59-d3af-d389d7a391a1"
      },
      "source": [
        "x = torch.zeros(3, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRXaXkE8LkXL"
      },
      "source": [
        "Com 1's:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ7LGUeYLom-",
        "outputId": "bef3b60b-7a7e-4a95-9ed4-f1706ed33d84"
      },
      "source": [
        "x = torch.ones(3, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXHtrwK6Lr3U"
      },
      "source": [
        "Também podemos informar um tipo de dados específico.\n",
        "\n",
        "Observe que por padrão o Tensor é criado com o tipo **float32**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJIR1R5lLvpP",
        "outputId": "e8ea32d5-d529-4e79-dd55-ab9d22ce243e"
      },
      "source": [
        "x = torch.empty(1, 4)\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoK1ugKuMEL8"
      },
      "source": [
        "Alterando o parâmetro **dtype** podemos transformar para **int**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVam37QBMRjT",
        "outputId": "26284e07-507a-4234-eeef-07111c598796"
      },
      "source": [
        "x = torch.empty(1, 4, dtype=torch.int)\n",
        "print(x.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwOuNXZaM4ho"
      },
      "source": [
        "Conseguimos ver o tamanho do Tensor através do método **size**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCnsb01zM-gw",
        "outputId": "97f4ae07-8585-4875-a7a6-0fc204d939a1"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv22cLniNFDz"
      },
      "source": [
        "Também podemos criar um Tensor a partir de uma outra estrutura de dados, como por exemplo, uma lista Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YMAecCWVbZ-",
        "outputId": "230f261f-faf3-4fb2-863a-741cf7034e60"
      },
      "source": [
        "x = torch.tensor([1,2,0.5])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0000, 2.0000, 0.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1tQe2GZVkub"
      },
      "source": [
        "## Operações\n",
        "\n",
        "Vejamos agora algumas operações básicas que podemos executar.\n",
        "\n",
        "Iniciaremos definindo dois Tensors com valores aleatórios:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2cYAXiDVrNf",
        "outputId": "e0f1bc41-9db4-4bb7-b017-a8a6a8357bba"
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2571, 0.2093],\n",
            "        [0.6417, 0.7596]])\n",
            "tensor([[0.9045, 0.7261],\n",
            "        [0.6304, 0.4823]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAVqzp5cVyEV"
      },
      "source": [
        "Adição básica (Element-wise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHZLzW1yVzkT",
        "outputId": "6cbbd91f-c3dd-4eb2-a086-356eae545db5"
      },
      "source": [
        "z = x + y \n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.1615, 0.9354],\n",
            "        [1.2722, 1.2419]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OffFbMlOV6EU"
      },
      "source": [
        "Da mesma forma, podemos expressar a adição da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74XNzU0AV80X",
        "outputId": "5ff4943b-6958-45f1-e79d-e3562e1f6a44"
      },
      "source": [
        "z = torch.add(x, y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.1615, 0.9354],\n",
            "        [1.2722, 1.2419]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkm49QNPWXUS"
      },
      "source": [
        "Subtração básica (Element-wise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z_c21zZWaFB",
        "outputId": "fb8ebe88-93e8-407d-ff38-21db32cb6f68"
      },
      "source": [
        "z = x - y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6474, -0.5168],\n",
            "        [ 0.0113,  0.2773]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F12npOPBWlXG"
      },
      "source": [
        "Da mesma forma, podemos expressar a subtração da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V9cz7R4WmzM",
        "outputId": "9ac154f5-be7f-48ba-fc85-13e6f9cfbd4d"
      },
      "source": [
        "z = torch.sub(x, y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.6474, -0.5168],\n",
            "        [ 0.0113,  0.2773]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLUZbk68WsNN"
      },
      "source": [
        "Multiplicação básica (Element-wise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgv6HTiyWtha",
        "outputId": "feff508a-cd3b-4751-c34f-7c88cc9ee26b"
      },
      "source": [
        "z = x * y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2325, 0.1520],\n",
            "        [0.4046, 0.3664]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6DVGdlqWwrE"
      },
      "source": [
        "Da mesma forma, podemos expressar a multiplicação da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLXNM45VWy6r",
        "outputId": "1909ded0-00a6-4c05-80c0-e9393df4449c"
      },
      "source": [
        "z = torch.mul(x, y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2325, 0.1520],\n",
            "        [0.4046, 0.3664]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_kgEe64W3Hk"
      },
      "source": [
        "Divisão básica (Element-wise):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWjYJ_7zW6AM",
        "outputId": "0b9d683b-d851-44e6-f580-9d3977af54b2"
      },
      "source": [
        "z = x / y\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2842, 0.2882],\n",
            "        [1.0179, 1.5749]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRYXmciSW8c9"
      },
      "source": [
        "Da mesma forma, podemos expressar a divisão da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbM6Q2VeW970",
        "outputId": "3493acf9-a3e6-4b62-d516-4a86ef599f37"
      },
      "source": [
        "z = torch.div(x, y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2842, 0.2882],\n",
            "        [1.0179, 1.5749]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDSAcowXHRu"
      },
      "source": [
        "Assim como os arrays NumPy, também podemos executar operações de slicing nos Tensors.\n",
        "\n",
        "Vejamos um exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws9X2nzoXOlV",
        "outputId": "f26e3c5e-58b5-4c84-f854-6e9bb059cc2e"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0300, 0.6424, 0.3933],\n",
            "        [0.5361, 0.9011, 0.3667],\n",
            "        [0.7730, 0.3112, 0.0898],\n",
            "        [0.7467, 0.7579, 0.6274],\n",
            "        [0.5114, 0.6914, 0.8884]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS0z8HRNXWn2"
      },
      "source": [
        "Obtendo todas as linhas e apenas uma coluna.\n",
        "\n",
        "Neste exemplo, vamos selecionar todas as linhas da primeira coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiiC2i3UXYbv",
        "outputId": "b73c3de8-5e6e-4437-985c-955a4d5d0878"
      },
      "source": [
        "print(x[:, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0300, 0.5361, 0.7730, 0.7467, 0.5114])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaSASW_YXyre"
      },
      "source": [
        "Obtendo todas as colunas e apenas uma linha.\n",
        "\n",
        "Neste exemplo, vamos selecionar todas as colunas e apenas a primeira linha:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kTnNttIYFD2",
        "outputId": "5c2e312b-662b-463b-a8e5-faa5a7261f2d"
      },
      "source": [
        "print(x[0, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0300, 0.6424, 0.3933])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJNf3yNQYOSr"
      },
      "source": [
        "Selecionando apenas um elemento.\n",
        "\n",
        "Neste exemplo, vamos selecionar apenas o elemento da segunda linha e segunda coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gzjUQzYVec",
        "outputId": "e32de5e6-a601-4db4-dba1-a22c84c87d63"
      },
      "source": [
        "print(x[1,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9011)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4NgUqB2YeMh"
      },
      "source": [
        "O método **item** nos traz o valor de fato, por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfPzy8zIYh4H",
        "outputId": "530141db-690d-452b-bdab-2f7569671558"
      },
      "source": [
        "print(x[1,1].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9010779857635498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4amEmPNYxeL"
      },
      "source": [
        "## Reshaping\n",
        "\n",
        "Agora vamos ver como podemos mudar a forma de um Tensor.\n",
        "\n",
        "Digamos que temos um Tensor de 4 linhas e 4 colunas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvVB3hUZY1XB",
        "outputId": "60496338-12bd-4d34-8fd0-fd657883a9d9"
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1643, 0.2254, 0.6051, 0.4687],\n",
            "        [0.2242, 0.8467, 0.2485, 0.0175],\n",
            "        [0.1061, 0.4917, 0.8280, 0.8843],\n",
            "        [0.0178, 0.2463, 0.1733, 0.2084]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj5J-ArFZQoM"
      },
      "source": [
        "Se quisermos alterar sua forma (**shape**) podemos usar o método **view**.\n",
        "\n",
        "Digamos que desejamos alterar o nosso Tensor para apenas 1 dimensão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJi8-roKZcsO",
        "outputId": "61547dcc-44fb-4e8e-e8f7-962cbb19a247"
      },
      "source": [
        "y = x.view(16)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1643, 0.2254, 0.6051, 0.4687, 0.2242, 0.8467, 0.2485, 0.0175, 0.1061,\n",
            "        0.4917, 0.8280, 0.8843, 0.0178, 0.2463, 0.1733, 0.2084])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU0sPkW5Zh2Y"
      },
      "source": [
        "Digamos que queremos que ele tenha 8 colunas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0TwOeMIZ0zB",
        "outputId": "dd4813ed-fa27-456f-8045-6d4312b0b383"
      },
      "source": [
        "y = x.view(-1, 8)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1643, 0.2254, 0.6051, 0.4687, 0.2242, 0.8467, 0.2485, 0.0175],\n",
            "        [0.1061, 0.4917, 0.8280, 0.8843, 0.0178, 0.2463, 0.1733, 0.2084]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEcyInpoZ_1j"
      },
      "source": [
        "O atributo **shape** nos permite vermos a forma de um Tensor, por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4lXRalUaEKb",
        "outputId": "d63edd0a-7ba7-4561-cba0-164a7f9f8256"
      },
      "source": [
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1paeablaKm0"
      },
      "source": [
        "## Conversões NumPy\n",
        "\n",
        "Vejamos como podemos fazer a conversão de arrays NumPy para Tensors e vice-versa.\n",
        "\n",
        "Primeiramente vamos criar um Tensor e em seguida vamos convertê-lo para um array NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOX7x5CPaomm",
        "outputId": "0050964b-1da5-45ed-a13f-782b1d954d0f"
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "print(type(a))\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'torch.Tensor'>\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvSfY5GAbB15"
      },
      "source": [
        "Tenha cuidado, pois ambos os objetos compartilham espaço em memória.\n",
        "\n",
        "Se modificarmos, por exemplo, o Tensor, automaticamente o array NumPy será afetado.\n",
        "\n",
        "Podemos ver um exemplo deste efeito ao usarmos o método **add_** que modifica um Tensor in-place:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzHD08ObQMI",
        "outputId": "bcede51d-d6d4-464d-cf1b-9f2b04f9518a"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1FZ6liPbY0y"
      },
      "source": [
        "Digamos agora que temos um array NumPy e queremos convertê-lo para um Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTSZlr1kbfIc",
        "outputId": "11c7135b-c286-4647-cd4c-e99608b43440"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.ones(5)\n",
        "print(a)\n",
        "print(type(a))\n",
        "\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Hzpcc7buz5"
      },
      "source": [
        "Da mesma forma, temos que ficar atentos ao compartilhamento de memória dos objetos.\n",
        "\n",
        "Se modificarmos o array NumPy, também estaremos automaticamente modificando o Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGEDnkYdb2EH",
        "outputId": "f40dd945-2a04-481a-9511-f941ce8b0fea"
      },
      "source": [
        "a += 1\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvj_mfdecuF_"
      },
      "source": [
        "## Operações na GPU\n",
        "\n",
        "Um dos grandes poderes de PyTorch é a sua capacidade de executar operações em uma GPU.\n",
        "\n",
        "Vejamos como podemos realizar essa tarefa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yT6NNTPec3m7"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    x = torch.ones(5, device=device)\n",
        "    y = torch.ones(5)\n",
        "    y = y.to(device)\n",
        "    z = x + y\n",
        "    print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHOGrihjdU_T"
      },
      "source": [
        "Neste caso, nosso Tensor **z** reside na GPU, se quisermos converter ele para um array NumPy, primeiro devemos passá-lo para a CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPk-H3iYdjB6",
        "outputId": "12bd6fe6-9181-41a9-f10c-bc30049400c2"
      },
      "source": [
        "z = z.to('cpu')\n",
        "print(z.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.28422618 0.28822917]\n",
            " [1.0179443  1.5749168 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUmopyx6eDVA"
      },
      "source": [
        "## Calculando Gradients\n",
        "\n",
        "Conhecendo o básico de Tensors, agora vamos aprender a usar o pacote **autograd** do PyTorch para calcular gradients.\n",
        "\n",
        "Os gradients são essenciais para a otimização de um modelo, portanto são um conceito muito importante dentro do contexto de Deep Learning.\n",
        "\n",
        "Começamos definindo um Tensor, observe que vamos setar o parâmetro **requires_grad** como **True**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BtC64Mp7i_H",
        "outputId": "ecb7a0ff-3eee-4432-fb4d-607a50fb4f62"
      },
      "source": [
        "x = torch.tensor(5.0, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5., requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drq7ARET76kN"
      },
      "source": [
        "Conforme executamos operações com esse Tensor, PyTorch irá criar um Grafo Computacional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY-EKsFF8ACR",
        "outputId": "86bcaff5-1864-4be6-d63c-6b974878731b"
      },
      "source": [
        "y = x - 2 \n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3., grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqH1FyNS8yBd"
      },
      "source": [
        "Vamos agora fazer mais uma operação com o nosso Tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbOJ3VI82Qn",
        "outputId": "5571696c-a863-4a5e-d185-7ef1b101ca69"
      },
      "source": [
        "z = y * (-4)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-12., grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvnFDurC9GX-"
      },
      "source": [
        "Para calcular o gradient usamos o método **backward**.\n",
        "\n",
        "Neste exemplo, vamos calcular o gradient $ \\frac{\\partial z}{\\partial x} $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvET9c699bnG",
        "outputId": "e6d5d2e2-0884-4943-e136-f76c3403edf9"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-4.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U3VzMxQABhs"
      },
      "source": [
        "Se eventualmente quisermos evitar que PyTorch crie as funções de gradient para rastrear o histórico de computações no grafo computacional, podemos usar algumas opções.\n",
        "\n",
        "Primeiramente, temos o método **detach**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXpGzAyRAViU",
        "outputId": "5c2b3af1-72ea-4c24-b9ff-81b44bce9899"
      },
      "source": [
        "y = x.detach()\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8p8My90Af5B"
      },
      "source": [
        "Também temos a opção de usar o gerenciador de contexto **with** com a função **no_grad**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRrvvIYGApMl",
        "outputId": "3064ad22-8126-4e5b-92e1-be2520f95d9c"
      },
      "source": [
        "with torch.no_grad():\n",
        "    y = x * z \n",
        "    print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-60.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chjG5dKzA0w9"
      },
      "source": [
        "Ou até mesmo o método **requires_grad_**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZQjXMepA5Xy",
        "outputId": "520efac6-37ca-48e7-9b88-3e57a944f802"
      },
      "source": [
        "print(x.requires_grad_(False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(5.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAOlERdzBq5-"
      },
      "source": [
        "É importante estarmos cientes de que quando chamamos o método **backward**, o gradient para este Tensor específico será acumulado no atributo **grad**, os valores serão somados.\n",
        "\n",
        "Por isso devemos ser cuidadosos.\n",
        "\n",
        "Vamos criar um exemplo de treinamento de um modelo com alguns *weights* para ilustrarmos essa ideia de que é necessária zerar o gradient para evitar o erro de acúmulo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhWd-TavCNep",
        "outputId": "8665f189-0e76-431d-959b-ccd92afe002c"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model_output = (weights * 3).sum()\n",
        "\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    weights.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJYDQGi9DFMd"
      },
      "source": [
        "O mesmo processo seria feito no contexto de um otimizador, por exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoM2Fv_HDKy7",
        "outputId": "cc38a423-73ed-42f7-b081-7794430d7e70"
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD([weights], lr=0.01)\n",
        "optimizer.step()\n",
        "print(weights)\n",
        "optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrUwOWYgRLS9"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "Em Machine Learning, a **[Backpropagation](https://en.wikipedia.org/wiki/Backpropagation)** é um algoritmo amplamente usado para treinar redes neurais feedforward. \n",
        "\n",
        "No ajuste de uma rede neural, o Backpropagation calcula o gradiente da função Loss em relação aos weights da rede para um único exemplo de entrada-saída e o faz de forma eficiente, ao contrário de um cálculo direto ingênuo do gradiente em relação a cada weight individualmente. Essa eficiência viabiliza o uso de métodos gradientes para treinar redes multicamadas, atualizando weights para minimizar Loss; O **gradient descent** ou variantes como o **stochastic gradient descent** são comumente usadas.\n",
        "\n",
        "A seguir vejamos um simples exemplo de como o backpropagation funciona:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpaAMwPqR-Ey"
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISOoFrpPSIEV"
      },
      "source": [
        "Agora faremos um **Forward pass** e vamos computar o Loss:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co1hollISLKG",
        "outputId": "daa30530-7a05-4d20-e543-17c5a43f797b"
      },
      "source": [
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RSm83DJST-Q"
      },
      "source": [
        "Por fim, faremos um **Backward pass** e imprimimos o valor do gradient:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFwhSD1mSbhv",
        "outputId": "f3f6d4d6-e7a5-446a-fe98-07eee2ff37ac"
      },
      "source": [
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NCiqyPwSnhp"
      },
      "source": [
        "O próximo passo seria atualizar os weights e fazer um novo **Forward/Backward pass** até que os weights estejam ajustados adequadamente e a rede neural esteja com a Loss minimizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJXcAApuUjEy"
      },
      "source": [
        "## Gradient Descent\n",
        "\n",
        "A seguir vamos ver um exemplo de Regressão Linear (previsão de valores contínuos) usando o algoritmo Gradient Descent para otimização da Loss.\n",
        "\n",
        "Como estamos trabalhando com Regressão Linear, então usaremos uma função que terá apenas uma combinação linear de nossos **weights** com os **inputs**: $ f = w * x $\n",
        "\n",
        "Vamos começar definindo um array **X** de amostras de treinamento e um array **Y** com os labels, iremos inicializar nossos **weights** em **0**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h37IsdBRUx87"
      },
      "source": [
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqCPUG9SV1ZM"
      },
      "source": [
        "Agora precisamos calcular a previsão do nosso modelo, nomearemos a função de **forward** para seguirmos a convenção da biblioteca PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd53GCEhV-nt"
      },
      "source": [
        "def forward(x):\n",
        "    return w * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef59szdAWFYZ"
      },
      "source": [
        "A seguir definimos a função Loss que irá depender dos valores **y** (valor real) e **y_predicted** (valor previsto pelo nosso modelo).\n",
        "\n",
        "Neste caso, como estamos trabalhando com Regressão Linear, vamos usar **Mean Squared Error**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rni8CupcWNL_"
      },
      "source": [
        "def loss(y, y_predicted):\n",
        "    return ((y_predicted - y)**2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB9mwTe-Wk48"
      },
      "source": [
        "E então precisamos manualmente calcular o gradient da função Loss em relação aos nossos parâmetros.\n",
        "\n",
        "Temos então que: $ MSE = \\frac{1}{N} * (w*x - y)^2 $\n",
        "\n",
        "E a derivada $ \\frac{dJ}{dw} = \\frac{1}{N} * 2x * (w*x - y) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yGsG-CNX5Wp"
      },
      "source": [
        "def gradient(x, y, y_predicted):\n",
        "    return np.dot(2*x, y_predicted-y).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSH77twuYDRT"
      },
      "source": [
        "E então podemos fazer uma previsão antes de treinarmos o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhPdTEcYFkl",
        "outputId": "8d3cbccb-5c87-4368-e657-5509a535976c"
      },
      "source": [
        "print(f'Previsão antes do treinamento: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previsão antes do treinamento: f(5) = 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoOxj0EmYP6_"
      },
      "source": [
        "E agora vamos treinar o nosso modelo para ajustar os weights adequadamente para que ele possa fazer previsões corretas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ULESINYXVD",
        "outputId": "b6b7e7a0-614d-4cc1-8af6-2d85f5cda996"
      },
      "source": [
        "learning_rate = 0.01\n",
        "n_iters = 13\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # Fazermos as previsões (forward pass)\n",
        "    y_pred = forward(X)\n",
        "    # Computamos a Loss\n",
        "    l = loss(Y, y_pred)\n",
        "    # Computamos o Gradient\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "    # Atualizamos os weights com o Gradient Descent\n",
        "    w -= learning_rate * dw\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Previsão após o treinamento: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: w = 1.200, loss = 30.00000000\n",
            "epoch 2: w = 1.680, loss = 4.79999924\n",
            "epoch 3: w = 1.872, loss = 0.76800019\n",
            "epoch 4: w = 1.949, loss = 0.12288000\n",
            "epoch 5: w = 1.980, loss = 0.01966083\n",
            "epoch 6: w = 1.992, loss = 0.00314574\n",
            "epoch 7: w = 1.997, loss = 0.00050331\n",
            "epoch 8: w = 1.999, loss = 0.00008053\n",
            "epoch 9: w = 1.999, loss = 0.00001288\n",
            "epoch 10: w = 2.000, loss = 0.00000206\n",
            "epoch 11: w = 2.000, loss = 0.00000033\n",
            "epoch 12: w = 2.000, loss = 0.00000005\n",
            "epoch 13: w = 2.000, loss = 0.00000001\n",
            "Previsão após o treinamento: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzp-PACobVSq"
      },
      "source": [
        "Anteriormente computamos o gradient manualmente, vejamos agora como podemos usar PyTorch para computá-lo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmBivzMTbi0C",
        "outputId": "59c48f6d-fe87-41e8-95a7-82b4ba9b9679"
      },
      "source": [
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "def loss(y, y_predicted):\n",
        "    return ((y_predicted - y)**2).mean()\n",
        "\n",
        "learning_rate = 0.02\n",
        "n_iters = 30\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # Fazermos as previsões (forward pass)\n",
        "    y_pred = forward(X)\n",
        "    # Computamos a Loss\n",
        "    l = loss(Y, y_pred)\n",
        "    # Computamos o Gradient (backward pass)\n",
        "    l.backward() # dl/dw\n",
        "    # Atualizamos os weights com o Gradient Descent\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    # Devemos zerar os parâmetros do gradient \n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Previsão após o treinamento: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: w = 0.600, loss = 30.00000000\n",
            "epoch 2: w = 1.020, loss = 14.70000076\n",
            "epoch 3: w = 1.314, loss = 7.20300007\n",
            "epoch 4: w = 1.520, loss = 3.52946997\n",
            "epoch 5: w = 1.664, loss = 1.72944093\n",
            "epoch 6: w = 1.765, loss = 0.84742588\n",
            "epoch 7: w = 1.835, loss = 0.41523871\n",
            "epoch 8: w = 1.885, loss = 0.20346695\n",
            "epoch 9: w = 1.919, loss = 0.09969879\n",
            "epoch 10: w = 1.944, loss = 0.04885240\n",
            "epoch 11: w = 1.960, loss = 0.02393769\n",
            "epoch 12: w = 1.972, loss = 0.01172951\n",
            "epoch 13: w = 1.981, loss = 0.00574747\n",
            "epoch 14: w = 1.986, loss = 0.00281625\n",
            "epoch 15: w = 1.991, loss = 0.00137996\n",
            "epoch 16: w = 1.993, loss = 0.00067618\n",
            "epoch 17: w = 1.995, loss = 0.00033133\n",
            "epoch 18: w = 1.997, loss = 0.00016235\n",
            "epoch 19: w = 1.998, loss = 0.00007955\n",
            "epoch 20: w = 1.998, loss = 0.00003898\n",
            "epoch 21: w = 1.999, loss = 0.00001910\n",
            "epoch 22: w = 1.999, loss = 0.00000936\n",
            "epoch 23: w = 1.999, loss = 0.00000459\n",
            "epoch 24: w = 2.000, loss = 0.00000225\n",
            "epoch 25: w = 2.000, loss = 0.00000110\n",
            "epoch 26: w = 2.000, loss = 0.00000054\n",
            "epoch 27: w = 2.000, loss = 0.00000026\n",
            "epoch 28: w = 2.000, loss = 0.00000013\n",
            "epoch 29: w = 2.000, loss = 0.00000006\n",
            "epoch 30: w = 2.000, loss = 0.00000003\n",
            "Previsão após o treinamento: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkM8jRS8cgZ_"
      },
      "source": [
        "Observe que ajustamos a taxa de aprendizado (**learning_rate**) e também aumentamos o número de iterações, eventualmente o algoritmo convergiu para a previsão correta como na forma manual.\n",
        "\n",
        "Feito isso, veremos como podemos usar PyTorch para automatizar toda a pipeline para nós, ou seja: **previsão**, **computação do gradient**, **computação da loss** e a **atualização dos parâmetros**.\n",
        "\n",
        "Resumindo, a pipeline do PyTorch funciona da seguinte forma:\n",
        "\n",
        "1. Design do Modelo (definir o tamanho do input e output, forward pass)\n",
        "2. Construir a função Loss e o Optimizer\n",
        "3. Loop de Treinamento\n",
        "    - forward pass: computar as previsões\n",
        "    - backward pass: computar os gradients\n",
        "    - atualizar os weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ2fBT0UcrGF",
        "outputId": "a8dcb673-6d2c-42be-c63b-a6911985b58f"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "learning_rate = 0.02\n",
        "n_iters = 30\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # Fazermos as previsões (forward pass)\n",
        "    y_pred = forward(X)\n",
        "    # Computamos a Loss\n",
        "    l = loss(Y, y_pred)\n",
        "    # Computamos o Gradient (backward pass)\n",
        "    l.backward() # dl/dw\n",
        "    # Atualizamos os weights com o Gradient Descent\n",
        "    optimizer.step()\n",
        "    # Devemos zerar os parâmetros do gradient \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Previsão após o treinamento: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: w = 0.600, loss = 30.00000000\n",
            "epoch 2: w = 1.020, loss = 14.70000076\n",
            "epoch 3: w = 1.314, loss = 7.20300007\n",
            "epoch 4: w = 1.520, loss = 3.52946997\n",
            "epoch 5: w = 1.664, loss = 1.72944093\n",
            "epoch 6: w = 1.765, loss = 0.84742588\n",
            "epoch 7: w = 1.835, loss = 0.41523871\n",
            "epoch 8: w = 1.885, loss = 0.20346695\n",
            "epoch 9: w = 1.919, loss = 0.09969879\n",
            "epoch 10: w = 1.944, loss = 0.04885240\n",
            "epoch 11: w = 1.960, loss = 0.02393769\n",
            "epoch 12: w = 1.972, loss = 0.01172951\n",
            "epoch 13: w = 1.981, loss = 0.00574747\n",
            "epoch 14: w = 1.986, loss = 0.00281625\n",
            "epoch 15: w = 1.991, loss = 0.00137996\n",
            "epoch 16: w = 1.993, loss = 0.00067618\n",
            "epoch 17: w = 1.995, loss = 0.00033133\n",
            "epoch 18: w = 1.997, loss = 0.00016235\n",
            "epoch 19: w = 1.998, loss = 0.00007955\n",
            "epoch 20: w = 1.998, loss = 0.00003898\n",
            "epoch 21: w = 1.999, loss = 0.00001910\n",
            "epoch 22: w = 1.999, loss = 0.00000936\n",
            "epoch 23: w = 1.999, loss = 0.00000459\n",
            "epoch 24: w = 2.000, loss = 0.00000225\n",
            "epoch 25: w = 2.000, loss = 0.00000110\n",
            "epoch 26: w = 2.000, loss = 0.00000054\n",
            "epoch 27: w = 2.000, loss = 0.00000026\n",
            "epoch 28: w = 2.000, loss = 0.00000013\n",
            "epoch 29: w = 2.000, loss = 0.00000006\n",
            "epoch 30: w = 2.000, loss = 0.00000003\n",
            "Previsão após o treinamento: f(5) = 10.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccu860ZRfPm4"
      },
      "source": [
        "Agora vamos substituir a nossa função manualmente implementada **forward** com o modelo do PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_KqQ4avfbi8",
        "outputId": "ab7329bc-b459-4282-c930-0ac4b9ba5a67"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "n_samples, n_features = X.shape\n",
        "print(f'Amostras: {n_samples}, Features: {n_features}')\n",
        "\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.03\n",
        "n_iters = 25\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # Fazermos as previsões (forward pass)\n",
        "    y_pred = model(X)\n",
        "    # Computamos a Loss\n",
        "    l = loss(Y, y_pred)\n",
        "    # Computamos o Gradient (backward pass)\n",
        "    l.backward() # dl/dw\n",
        "    # Atualizamos os weights com o Gradient Descent\n",
        "    optimizer.step()\n",
        "    # Devemos zerar os parâmetros do gradient \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        [w, b] = model.parameters()\n",
        "        print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Previsão após o treinamento: f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amostras: 4, Features: 1\n",
            "epoch 1: w = 0.999, loss = 36.60515594\n",
            "epoch 2: w = 1.495, loss = 9.11420059\n",
            "epoch 3: w = 1.742, loss = 2.26942635\n",
            "epoch 4: w = 1.866, loss = 0.56519234\n",
            "epoch 5: w = 1.927, loss = 0.14086476\n",
            "epoch 6: w = 1.958, loss = 0.03521217\n",
            "epoch 7: w = 1.974, loss = 0.00890393\n",
            "epoch 8: w = 1.981, loss = 0.00235122\n",
            "epoch 9: w = 1.985, loss = 0.00071731\n",
            "epoch 10: w = 1.987, loss = 0.00030812\n",
            "epoch 11: w = 1.988, loss = 0.00020393\n",
            "epoch 12: w = 1.989, loss = 0.00017571\n",
            "epoch 13: w = 1.989, loss = 0.00016645\n",
            "epoch 14: w = 1.989, loss = 0.00016195\n",
            "epoch 15: w = 1.990, loss = 0.00015867\n",
            "epoch 16: w = 1.990, loss = 0.00015574\n",
            "epoch 17: w = 1.990, loss = 0.00015293\n",
            "epoch 18: w = 1.990, loss = 0.00015019\n",
            "epoch 19: w = 1.990, loss = 0.00014750\n",
            "epoch 20: w = 1.990, loss = 0.00014487\n",
            "epoch 21: w = 1.990, loss = 0.00014228\n",
            "epoch 22: w = 1.990, loss = 0.00013973\n",
            "epoch 23: w = 1.990, loss = 0.00013723\n",
            "epoch 24: w = 1.990, loss = 0.00013478\n",
            "epoch 25: w = 1.991, loss = 0.00013237\n",
            "Previsão após o treinamento: f(5) = 9.980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5ywSSZ_hxUs"
      },
      "source": [
        "## Regressão Linear\n",
        "\n",
        "Agora que sabemos como otimizar o nosso modelo atualizando os seus parâmetros, vejamos um exemplo mais concreto de como podemos implementar a Regressão Linear com PyTorch.\n",
        "\n",
        "Também usaremos as bibliotecas scikit-learn e matplotlib para nos auxiliar nessa tarefa.\n",
        "\n",
        "Nossas etapas serão basicamente:\n",
        "\n",
        "1. Preparar os dados\n",
        "2. Definir o Modelo\n",
        "3. Definir a função Loss e o Optimizer\n",
        "4. Treinar o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "iOI-1TBxiGUk",
        "outputId": "253d7055-bfef-4149-bece-20a51dd7d9b6"
      },
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "# Preparando os dados\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=200, n_features=1, noise=12)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# Definindo o modelo\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# Definindo a função Loss e o Optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Loop de treinamento\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # forward pass e loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # atualizar os weights\n",
        "    optimizer.step()\n",
        "    # zerar o gradient\n",
        "    optimizer.zero_grad()\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print(f'Epoch: {epoch+1}, Loss = {loss.item():.4f}')\n",
        "\n",
        "# Plotamos o resultado\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, c='blue', lw=2.5);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, Loss = 538.3498\n",
            "Epoch: 10, Loss = 471.2179\n",
            "Epoch: 15, Loss = 415.5769\n",
            "Epoch: 20, Loss = 369.4540\n",
            "Epoch: 25, Loss = 331.2164\n",
            "Epoch: 30, Loss = 299.5122\n",
            "Epoch: 35, Loss = 273.2218\n",
            "Epoch: 40, Loss = 251.4182\n",
            "Epoch: 45, Loss = 233.3335\n",
            "Epoch: 50, Loss = 218.3318\n",
            "Epoch: 55, Loss = 205.8860\n",
            "Epoch: 60, Loss = 195.5595\n",
            "Epoch: 65, Loss = 186.9905\n",
            "Epoch: 70, Loss = 179.8790\n",
            "Epoch: 75, Loss = 173.9766\n",
            "Epoch: 80, Loss = 169.0771\n",
            "Epoch: 85, Loss = 165.0098\n",
            "Epoch: 90, Loss = 161.6329\n",
            "Epoch: 95, Loss = 158.8289\n",
            "Epoch: 100, Loss = 156.5004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv5DbC-dzV7s"
      },
      "source": [
        "## Regressão Logística\n",
        "\n",
        "Dessa vez, vamos implementar a Regressão Logística na tarefa de classificação de dados biomédicos (câncer de mama).\n",
        "\n",
        "Vamos seguir a mesma pipeline anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY2NyRMuzovT",
        "outputId": "40329a30-5ea5-4fbd-d290-c13502c6e050"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preparando os dados\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Scaling dos dados\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Convertendo para Tensor\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# Reshaping\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# Definindo o Modelo\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        y_predicted = torch.sigmoid(self.linear(x))\n",
        "        return y_predicted \n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# Definindo o Loss e o Optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Treinamos o Modelo\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass e loss\n",
        "    y_predicted = model(X_train)\n",
        "    loss = criterion(y_predicted, y_train)\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Atualiza os weights\n",
        "    optimizer.step()\n",
        "    # Zerar o gradient\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 5 == 0:\n",
        "        print(f'Epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Avaliando o Modelo (Accuracy)\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'Accuracy = {acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, loss = 0.5857\n",
            "Epoch: 10, loss = 0.5285\n",
            "Epoch: 15, loss = 0.4840\n",
            "Epoch: 20, loss = 0.4486\n",
            "Epoch: 25, loss = 0.4197\n",
            "Epoch: 30, loss = 0.3957\n",
            "Epoch: 35, loss = 0.3752\n",
            "Epoch: 40, loss = 0.3576\n",
            "Epoch: 45, loss = 0.3423\n",
            "Epoch: 50, loss = 0.3288\n",
            "Epoch: 55, loss = 0.3167\n",
            "Epoch: 60, loss = 0.3059\n",
            "Epoch: 65, loss = 0.2962\n",
            "Epoch: 70, loss = 0.2874\n",
            "Epoch: 75, loss = 0.2793\n",
            "Epoch: 80, loss = 0.2718\n",
            "Epoch: 85, loss = 0.2650\n",
            "Epoch: 90, loss = 0.2586\n",
            "Epoch: 95, loss = 0.2527\n",
            "Epoch: 100, loss = 0.2472\n",
            "Accuracy = 0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmbDz-ui4GDI"
      },
      "source": [
        "## Dataset e DataLoader\n",
        "\n",
        "Nesta seção veremos como usar as classes **Dataset** e **DataLoader** da biblioteca PyTorch.\n",
        "\n",
        "Mas antes é importante estarmos familiarizados com alguns termos:\n",
        "\n",
        "- **epoch**: uma passagem forward e backward de todas as amostras de treinamento\n",
        "- **batch_size**: número de amostras de treinamento em uma passagem forward e backward\n",
        "- **número de iterações**: número de passagens, cada passagem usando um **batch_size** de número de amostras\n",
        "\n",
        "Por exemplo: 100 amostras, batch_size=20 ---> 100/20 = 5 iterações por epoch.\n",
        "\n",
        "Primeiramente vamos fazer o download dos dados que precisaremos para este experimento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYAWwwq855NW",
        "outputId": "ec3ff2ea-6d89-46f6-ae2e-9c5e3e582afd"
      },
      "source": [
        "!wget -nc https://gist.githubusercontent.com/the-akira/c568feeebb6903d4dc68e3d1f90c089d/raw/d9f8be0d85ff982b8d952a6ec9cb71120419e70f/wine.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 12:55:17--  https://gist.githubusercontent.com/the-akira/c568feeebb6903d4dc68e3d1f90c089d/raw/d9f8be0d85ff982b8d952a6ec9cb71120419e70f/wine.csv\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10889 (11K) [text/plain]\n",
            "Saving to: ‘wine.csv’\n",
            "\n",
            "wine.csv            100%[===================>]  10.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-25 12:55:18 (107 MB/s) - ‘wine.csv’ saved [10889/10889]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF5rXOnK7Hdj"
      },
      "source": [
        "Vamos agora definir o nosso conjunto de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At1n7kyS5D8L",
        "outputId": "356cb943-e4e2-4e60-befb-99d1df1761a6"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:,1:])\n",
        "        self.y = torch.from_numpy(xy[:,[0]])\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6kGqmEq7jdc"
      },
      "source": [
        "Criamos o **DataLoader** e iteramos sob ele:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgEsZ0TK64gi",
        "outputId": "82210c85-6a9e-4087-e916-999a4bce9a94"
      },
      "source": [
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.2340e+01, 2.4500e+00, 2.4600e+00, 2.1000e+01, 9.8000e+01, 2.5600e+00,\n",
            "         2.1100e+00, 3.4000e-01, 1.3100e+00, 2.8000e+00, 8.0000e-01, 3.3800e+00,\n",
            "         4.3800e+02],\n",
            "        [1.3110e+01, 1.0100e+00, 1.7000e+00, 1.5000e+01, 7.8000e+01, 2.9800e+00,\n",
            "         3.1800e+00, 2.6000e-01, 2.2800e+00, 5.3000e+00, 1.1200e+00, 3.1800e+00,\n",
            "         5.0200e+02],\n",
            "        [1.2880e+01, 2.9900e+00, 2.4000e+00, 2.0000e+01, 1.0400e+02, 1.3000e+00,\n",
            "         1.2200e+00, 2.4000e-01, 8.3000e-01, 5.4000e+00, 7.4000e-01, 1.4200e+00,\n",
            "         5.3000e+02],\n",
            "        [1.4100e+01, 2.0200e+00, 2.4000e+00, 1.8800e+01, 1.0300e+02, 2.7500e+00,\n",
            "         2.9200e+00, 3.2000e-01, 2.3800e+00, 6.2000e+00, 1.0700e+00, 2.7500e+00,\n",
            "         1.0600e+03]]) tensor([[2.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQoNnX-v7tAx"
      },
      "source": [
        "Veja que temos 4 vetores de features e 4 labels (isso ocorre porque definimos o **batch_size** como 4).\n",
        "\n",
        "Também podemos iterar sob TODO o **DataLoader**.\n",
        "\n",
        "Vamos simular o treinamento de um modelo para exemplificar a ideia:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSeyv7ni7X9_",
        "outputId": "c3f175ff-5988-4120-ebd6-72c04eb903cd"
      },
      "source": [
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, step: {i+1}/{n_iterations}, inputs: {inputs.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "178 45\n",
            "Epoch: 1/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 1/2, step: 45/45, inputs: torch.Size([2, 13])\n",
            "Epoch: 2/2, step: 5/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 10/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 15/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 20/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 25/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 30/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 35/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 40/45, inputs: torch.Size([4, 13])\n",
            "Epoch: 2/2, step: 45/45, inputs: torch.Size([2, 13])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoheH7Z482WU"
      },
      "source": [
        "Neste caso, o nosso **batch_size** é 4 e o número de features em cada **batch** é 13."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAEKqSsIKzd1"
      },
      "source": [
        "## Dataset Transforms\n",
        "\n",
        "PyTorch nos possibilita usar transformadores para transformar automaticamente os nossos dados.\n",
        "\n",
        "Para saber mais detalhes sobre eles, você pode visitar a [documentação oficial](https://pytorch.org/vision/stable/transforms.html).\n",
        "\n",
        "Anteriormente escrevemos um conjunto de dados customizado, vamos expandir essa classe para suportar os nossos transformadores.\n",
        "\n",
        "Vejamos um exemplo a seguir:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzLeciROXag"
      },
      "source": [
        "class WineDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.x = xy[:,1:]\n",
        "        self.y = xy[:,[0]]\n",
        "        self.n_samples = xy.shape[0]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x[index], self.y[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        \n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "    \"\"\"\n",
        "    Transformador que converte os dados para um Torch Tensor\n",
        "    \"\"\"\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    \"\"\"\n",
        "    Transformador que multiplica os inputs por um fator informado\n",
        "    \"\"\"\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "    \n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGltN7CZQnVx"
      },
      "source": [
        "Convertendo os arrays NumPy para Tensor com o Transformador **ToTensor**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj_Rm_XvQsDz",
        "outputId": "f2ae620e-afe4-4903-eb03-517ed5c86865"
      },
      "source": [
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xufuPE05Qu4o"
      },
      "source": [
        "Vamos agora fazer uma composição de transformadores.\n",
        "\n",
        "Primeiro vamos transformar os arrays NumPy para Tensor usando **ToTensor**.\n",
        "\n",
        "Depois vamos multiplicar os inputs com o transformador **MulTransform**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJMQ8RAYQy0Z",
        "outputId": "d5be3b1e-d54c-4642-be04-a35e334de516"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
            "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
            "        2.1300e+03])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvot81aqRrjO"
      },
      "source": [
        "## Softmax e Cross Entropy\n",
        "\n",
        "A [função softmax](https://en.wikipedia.org/wiki/Softmax_function) é uma generalização da função logística para múltiplas dimensões. É usado em regressão logística multinomial e é frequentemente usado como a última função de ativação de uma rede neural para normalizar a saída de uma rede para uma distribuição de probabilidade sobre classes de saída previstas, com base no axioma de escolha de Luce.\n",
        "\n",
        "A seguir, vamos ver como podemos implementar a função softmax com NumPy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr7GJcUQSiJc",
        "outputId": "34549e4d-57ad-486f-d754-cd42689049b7"
      },
      "source": [
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print(f'Softmax Numpy: {outputs}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Softmax Numpy: [0.65900114 0.24243297 0.09856589]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mj-xeE8S0BK"
      },
      "source": [
        "A seguir, vamos ver como podemos implementar a função softmax com PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuwJ7dbVS1Qz",
        "outputId": "2911c9d1-cddf-4af2-84f4-cb410a6ee3a4"
      },
      "source": [
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0)\n",
        "print(f'Softmax PyTorch: {outputs}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Softmax PyTorch: tensor([0.6590, 0.2424, 0.0986])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cd-Qnq1TH6c"
      },
      "source": [
        "Muitas vezes a função softmax é combinada com a **[Cross-Entropy](https://en.wikipedia.org/wiki/Cross_entropy)**, que mede a performance de nosso modelo de classificação cuja saída é uma probabilidade entre 0 e 1, ela pode ser usada em problemas de múltiplas classes. A loss aumenta conforme a probabilidade prevista diverge da label verdadeira, ou seja, quanto melhor a nossa previsão, menor será a loss.\n",
        "\n",
        "Vejamos a seguir como podemos implementar a **Cross-Entropy**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFglyueTT924"
      },
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQrxPKqWUOR2"
      },
      "source": [
        "**Importante**: y deve ser **hot encoded**.\n",
        "\n",
        "Por exemplo:\n",
        "\n",
        "- Se class 0: **[1 0 0]**\n",
        "- Se class 1: **[0 1 0]**\n",
        "- Se class 2: **[0 0 1]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjYJlrCVUvvl"
      },
      "source": [
        "y = np.array([1, 0, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4aBGz6JU1EI"
      },
      "source": [
        "Observe que **y_pred** possui probabilidades:\n",
        "\n",
        "- **y_pred_good**: a classe 0 possui probabilidade boa, ou seja, ela é alta para a classe 0.\n",
        "- **y_pred_bad**: a classe 0 possui probabilidade ruim, ou seja, ela é baixa para a classe 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo9z_s8sU0Nn",
        "outputId": "871dffbe-0e59-4c70-afef-2e7b520bb398"
      },
      "source": [
        "y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "\n",
        "l1 = cross_entropy(y, y_pred_good)\n",
        "l2 = cross_entropy(y, y_pred_bad)\n",
        "\n",
        "print(f'Loss 1 NumPy = {l1:.4f}')\n",
        "print(f'Loss 2 NumPy = {l2:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 1 NumPy = 0.3567\n",
            "Loss 2 NumPy = 2.3026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b_iAizPVrJS"
      },
      "source": [
        "Observe que a primeira previsão possui uma loss baixa, pois está adequada.\n",
        "\n",
        "Já a segunda previsão possui uma loss alta, pois está inadequada.\n",
        "\n",
        "Vejamos agora podemos replicar este experimento com PyTorch:\n",
        "\n",
        "- Dessa vez não usaremos softmax na última layer, pois já é implementado.\n",
        "\n",
        "- Também não devemos usar **hot encoding** em nosso y.\n",
        "\n",
        "- Também não teremos softmax em nossas previsões y_pred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yfu82m1V8QL",
        "outputId": "a0852053-2389-4b4f-cf24-28cc8307a08e"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "y = torch.tensor([0])\n",
        "y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "\n",
        "print(f'Loss 1 Torch = {l1.item():.4f}')\n",
        "print(f'Loss 2 Torch = {l2.item():.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 1 Torch = 0.4170\n",
            "Loss 2 Torch = 1.8406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aasdlsQwXShv"
      },
      "source": [
        "Para obter as previsões, fazemos da seguinte forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5mbDXkVXVIo",
        "outputId": "4f417168-ea0f-4370-b77b-fc0de679bcdc"
      },
      "source": [
        "_, predictions1 = torch.max(y_pred_good, 1)\n",
        "_, predictions2 = torch.max(y_pred_bad, 1)\n",
        "\n",
        "print(f'Previsão 1: {predictions1}')\n",
        "print(f'Previsão 2: {predictions2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Previsão 1: tensor([0])\n",
            "Previsão 2: tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkZSzRAPXrwt"
      },
      "source": [
        "Veja que em ambos os casos estamos escolhendo o valor com maior probabilidade, que é o **2.0**, indexado em **predictions1** por **0** e em **predictions2** por **1**.\n",
        "\n",
        "É importante estarmos cientes que a Loss em PyTorch nos possibilita trabalhar com múltiplas amostras. \n",
        "\n",
        "Vamos então aumentar nossas amostras para ver esste exemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDDpfK5eYb1B",
        "outputId": "83b3b605-07a1-48a0-bbb0-7893b4f82d04"
      },
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "# 3 amostras\n",
        "y = torch.tensor([2, 0, 1])\n",
        "# n_amostras x n_classes = 3 x 3\n",
        "y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [2.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
        "y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0.3, 1.0, 2.1], [0.1, 3.0, 0.1]])\n",
        "\n",
        "l1 = loss(y_pred_good, y)\n",
        "l2 = loss(y_pred_bad, y)\n",
        "\n",
        "print(f'Loss 1 Torch = {l1.item():.4f}')\n",
        "print(f'Loss 2 Torch = {l2.item():.4f}')\n",
        "\n",
        "_, predictions1 = torch.max(y_pred_good, 1)\n",
        "_, predictions2 = torch.max(y_pred_bad, 1)\n",
        "\n",
        "print(f'Previsão 1: {predictions1}')\n",
        "print(f'Previsão 2: {predictions2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss 1 Torch = 0.3018\n",
            "Loss 2 Torch = 1.5642\n",
            "Previsão 1: tensor([2, 0, 1])\n",
            "Previsão 2: tensor([0, 2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7wcLB35a2XA"
      },
      "source": [
        "Observe que a nossa primeira previsão é correta e está de acordo com **y**, já a segunda previsão está incorreta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlyGjOn1kyVa"
      },
      "source": [
        "## Funções de Ativação\n",
        "\n",
        "Em redes neurais artificiais, a função de ativação de um nó define a saída desse nó dada uma entrada ou conjunto de entradas.\n",
        "\n",
        "As funções de ativação são uma característica importante das redes neurais artificiais.\n",
        "\n",
        "Elas são responsáveis por aplicar uma transformação não-linear e então decidir se um neurônio deve ser ativado ou não.\n",
        "\n",
        "Através de suas transformações não-lineares as nossas redes neurais podem aprender \"melhor\", podendo resolver problemas mais complexos.\n",
        "\n",
        "A seguir temos uma lista das funções de ativação mais populares:\n",
        "\n",
        "1. Step Function\n",
        "2. Sigmoid\n",
        "3. TanH\n",
        "4. ReLU\n",
        "5. Leaky ReLU\n",
        "6. Softmax\n",
        "\n",
        "## Multilayer Feed-Forward Neural Network\n",
        "\n",
        "A seguir vamos implementar uma Multilayer Network capaz de fazer classificação de dígitos escritos a mão, usaremos o famosos conjunto de dados MNIST para solucionar este problema.\n",
        "\n",
        "Usaremos vários conceitos que já aprendemos anteriormente, como o **DataLoader** para carregar o nosso conjunto de dados, aplicaremos também um transfomador nos dados.\n",
        "\n",
        "Implementaremos a nossa Rede Neural com uma layer de input, hidden layer e output layer e também aplicaremos as funções de ativação.\n",
        "\n",
        "Iremos então setar uma função Loss e o Otimizador e definiremos um loop de treinamento para treinar o modelo (rede neural).\n",
        "\n",
        "Por fim, iremos avaliar o modelo e calcular a **Accuracy** dele."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_vRa8Tjk_93",
        "outputId": "85582d63-7a4b-4660-cec2-f386df2cbc8a"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# configuração do dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyper parameters\n",
        "input_size = 784 # dimensão da imagem = 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10 # números de 0 a 9\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='.', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='.', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "examples = iter(train_loader)\n",
        "samples, labels = examples.next()\n",
        "print(samples.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVO1cHppqcuK"
      },
      "source": [
        "Observe que temos um batch de 100 amostras, com apenas 1 canal de cores de dimensão 28 x 28.\n",
        "\n",
        "Também temos um vetor de 100 labels, indicando a classe a qual cada imagem pertence.\n",
        "\n",
        "Vamos plotar algumas imagens para vermos os dados que estamos trabalhando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "NzeTXjW7qnL-",
        "outputId": "f805dec4-1089-4fb5-8eca-93aa97cf46b5"
      },
      "source": [
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSWb7C-brFJX"
      },
      "source": [
        "Agora vamos construir a nossa Rede Neural (Modelo Classificador) usando os conceitos que aprendemos até então:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZElaQfBrRAq"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOCeAjiPr6xL"
      },
      "source": [
        "Com o nosso Modelo definido, podemos instanciá-lo para usar ele:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Md3z4P-r-L4"
      },
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Icy2rosD1o"
      },
      "source": [
        "Definimos a função Loss e o Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sYYBX-UsGGz"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fev5qt6bsPk9"
      },
      "source": [
        "Treinamos o Modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fm3JOlCsSrQ",
        "outputId": "1eccd48f-f2e0-497e-e26d-509ccf21abcb"
      },
      "source": [
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # 100, 1, 28, 28 -> 100, 784\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backwards\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'epoch: {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1 / 2, step 100 / 600, loss = 0.4185\n",
            "epoch: 1 / 2, step 200 / 600, loss = 0.2613\n",
            "epoch: 1 / 2, step 300 / 600, loss = 0.2317\n",
            "epoch: 1 / 2, step 400 / 600, loss = 0.2591\n",
            "epoch: 1 / 2, step 500 / 600, loss = 0.1763\n",
            "epoch: 1 / 2, step 600 / 600, loss = 0.1951\n",
            "epoch: 2 / 2, step 100 / 600, loss = 0.1413\n",
            "epoch: 2 / 2, step 200 / 600, loss = 0.1762\n",
            "epoch: 2 / 2, step 300 / 600, loss = 0.1871\n",
            "epoch: 2 / 2, step 400 / 600, loss = 0.1090\n",
            "epoch: 2 / 2, step 500 / 600, loss = 0.2516\n",
            "epoch: 2 / 2, step 600 / 600, loss = 0.2131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA9uxDKHtdUa"
      },
      "source": [
        "Por fim, calculamos a **Accuracy** do modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRjT5qBFtfvg",
        "outputId": "046f9073-cca0-46b7-c85b-31e6f0f10168"
      },
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        n_samples += labels.shape[0]\n",
        "        n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy = {acc}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 95.43%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6jwJbZx3K6I"
      },
      "source": [
        "## Referências\n",
        "\n",
        "- [Deep Learning With PyTorch](https://www.youtube.com/watch?v=c36lUUr864M&t=3814s&ab_channel=PythonEngineer)\n",
        "- [PyTorch](https://pytorch.org/)"
      ]
    }
  ]
}